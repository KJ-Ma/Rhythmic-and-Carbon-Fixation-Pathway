# 1. Install CRAN source packages

# Set CRAN mirror to Tsinghua University
local({
  r <- getOption("repos")  
  r["CRAN"] <- "http://mirrors.tuna.tsinghua.edu.cn/CRAN/"   
  options(repos = r)
}) 

# Install and load the required packages
package_list <- c("ggplot2", "RColorBrewer", "randomForest", "caret", "dplyr", "ggrepel", "pheatmap")

# Install missing packages and load all
for(p in package_list) {
  if(!suppressWarnings(suppressMessages(require(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))) {
    install.packages(p, warn.conflicts = FALSE)
    suppressWarnings(suppressMessages(library(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))
  }
}

# 2. Data loading and preprocessing

# Load the species abundance table
otutable <- read.table("final_rhythmic_ASV_mudX.txt", sep = "\t", header = TRUE, check.names = FALSE, comment.char = "", row.names = 1)

# Load metadata and environmental data
fastmap <- read.table("metadata_mudX.txt", sep = "\t", header = TRUE, check.names = FALSE, comment.char = "", row.names = 1)
env <- read.table("../env_mudX.txt", sep = "\t", header = TRUE, check.names = FALSE, comment.char = "", row.names = 1)

# Transpose and rename ASV columns
otutable.t <- t(otutable)
otutable.t <- as.data.frame(otutable.t)
colnames(otutable.t)[1:321] <- paste0("ASV_", 1:321)

# Add the target variable for prediction: Temperature
otutable.t$Temperature <- env$Temperature

# Split data into Discovery (train) and Validation (test) sets
fastmap_Discovery <- subset(fastmap, phase == "Discovery")
fastmap_validation <- subset(fastmap, phase == "Validation")

trainset <- otutable.t[rownames(fastmap_Discovery), ]
testset <- otutable.t[rownames(fastmap_validation), ]

# Set random seed for reproducibility
set.seed(500)

# 3. Random Forest model training

# Train a random forest model
rf.train <- randomForest(Temperature ~ ., 
                         data = trainset, 
                         ntree = 1000, 
                         importance = TRUE, 
                         proximity = TRUE)
rf.train  # View model performance
plot(rf.train)  # Plot the decision tree

# 4. Feature importance extraction

# Extract and save feature importance
imp <- as.data.frame(rf.train$importance)
imp <- imp[order(imp$`%IncMSE`, decreasing = TRUE),]

if (!dir.exists("randomforest_out")) {
  dir.create("randomforest_out")
}

write.table(imp, file = "randomforest_out/importance_feature.txt", quote = FALSE, sep = '\t', row.names = TRUE, col.names = TRUE)
head(imp)

# Plot variable importance
varImpPlot(rf.train)

# 5. Visualize top 20 important features

imp_sub <- imp[1:20, ]
imp_sub$taxa <- rownames(imp_sub)
imp_sub$taxa <- factor(imp_sub$taxa, order = TRUE, levels = rev(imp_sub$taxa))

p <- ggplot(data = imp_sub, mapping = aes(x = taxa, y = `%IncMSE`)) + 
  geom_bar(stat = "identity") + coord_flip() + theme_bw() +
  theme(panel.grid = element_blank(),
        axis.text.x = element_text(colour = "black"),
        axis.text.y = element_text(colour = "black"),
        panel.border = element_rect(colour = "black"),
        legend.key = element_blank(), plot.title = element_text(hjust = 0.5))
p

# 6. Cross-validation for Random Forest

# 10-fold cross-validation repeated 5 times
set.seed(123)
result <- replicate(5, rfcv(trainset[,-ncol(trainset)], trainset$Temperature, cv.fold = 10), simplify = FALSE)    
error.cv <- sapply(result, "[[", "error.cv")

# Plot cross-validation error
matplot(result[[1]]$n.var, cbind(rowMeans(error.cv), error.cv), type = "l",
        lwd = c(2, rep(1, ncol(error.cv))), col = 1, lty = 1, log = "x",
        xlab = "Number of variables", ylab = "CV Error")

# Save cross-validation results
cv.result <- cbind(result[[1]]$n.var, rowMeans(error.cv), error.cv)
write.table(cv.result, file = "randomforest_out/rfcv_result.txt", quote = FALSE, sep = '\t', row.names = TRUE, col.names = TRUE)
cv.result

# 7. Model tuning with optimized mtry

# Formula using the top 10 important variables
rf.formula <- as.formula(paste0("Temperature ~", paste(row.names(imp)[1:10], collapse = "+")))
rf.formula

# Train model using caret with optimized mtry
train.res <- train(rf.formula, 
                   data = trainset, 
                   method = 'rf', 
                   trControl = trainControl(method = 'cv', number = 10, search = 'grid'))
train.res

# Build Random Forest model with optimized mtry
model <- randomForest(rf.formula, 
                      data = trainset, 
                      ntree = 500, 
                      mtry = 3, 
                      importance = TRUE, 
                      proximity = TRUE)
model

# 8. Testing model accuracy on test data

# Make predictions on the test set
pred1 <- predict(model, newdata = testset, type = "response")
pred_result <- data.frame(observed = testset$Temperature, predict = pred1)

# Save prediction results
write.table(pred_result, file = "randomforest_out/testset_predict.txt", quote = FALSE, sep = '\t', row.names = TRUE, col.names = TRUE)

# Correlation test and fit plot
cor <- cor.test(pred_result[,1], pred_result[,2], method = "spearman")

m <- lm(observed ~ predict, pred_result)
p <- ggplot(pred_result, aes(predict, observed)) +
  geom_point() + geom_smooth(method = "lm") +
  labs(title = paste("rho = " , round(cor$estimate, digits = 3), 
                     ", P = " , signif(cor$p.value, digits = 3), 
                     ", R2 = ", round(summary(m)$r.squared, digits = 3), sep = "")) + 
  theme_bw() + theme(panel.grid = element_blank(),
                     axis.text.x = element_text(colour = "black"),
                     axis.text.y = element_text(colour = "black"),
                     panel.border = element_rect(colour = "black"),
                     legend.key = element_blank(), plot.title = element_text(hjust = 0.5))

ggsave("randomforest_out/10_marker_ASVs_validate.pdf", p, width = 4, height = 4)
ggsave("randomforest_out/10_marker_ASVs_validate.png", p, width = 4, height = 4, bg = "white")

# 9. Testing model accuracy on training data

# Make predictions on the train set
pred2 <- predict(model, newdata = trainset, type = "response")
pred_result2 <- data.frame(observed = trainset$Temperature, predict = pred2)

# Correlation test and fit plot
cor2 <- cor.test(pred_result2[,1], pred_result2[,2], method = "spearman")

m2 <- lm(observed ~ predict, pred_result2)
p2 <- ggplot(pred_result2, aes(predict, observed)) +
  geom_point() + geom_smooth(method = "lm") +
  labs(title = paste("rho = " , round(cor2$estimate, digits = 3), 
                     ", P = " , signif(cor2$p.value, digits = 3), 
                     ", R2 = ", round(summary(m2)$r.squared, digits = 3), sep = "")) + 
  theme_bw() + theme(panel.grid = element_blank(),
                     axis.text.x = element_text(colour = "black"),
                     axis.text.y = element_text(colour = "black"),
                     panel.border = element_rect(colour = "black"),
                     legend.key = element_blank(), plot.title = element_text(hjust = 0.5))

ggsave("randomforest_out/10_marker_ASVs_train.pdf", p2, width = 4, height = 4)
ggsave("randomforest_out/10_marker_ASVs_train.png", p2, width = 4, height = 4, bg = "white")
